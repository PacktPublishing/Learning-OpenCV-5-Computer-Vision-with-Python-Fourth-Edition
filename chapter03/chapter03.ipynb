{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2532e053",
   "metadata": {},
   "source": [
    "# Chapter 3: Processing Images with OpenCV\n",
    "\n",
    "This Jupyter Notebook allows you to interactively edit and run a subset of the code samples from the corresponding chapter in our book, *Learning OpenCV 5 Computer Vision with Python 3*.\n",
    "\n",
    "Any Jupyter server should be capable of running the Notebook, even if the sample input images files are not available in the server's local filesystem. For example, you can run the Notebook in Google Colab by opening the following link in your Web browser: https://colab.research.google.com/github/PacktPublishing/Learning-OpenCV-5-Computer-Vision-with-Python-Fourth-Edition/blob/main/chapter03/chapter03.ipynb. Specifically, this link opens the Notebook's latest version, hosted on GitHub.\n",
    "\n",
    "For additional code samples and instructions, please refer to the book and to the GitHub repository at https://github.com/PacktPublishing/Learning-OpenCV-5-Computer-Vision-with-Python-Fourth-Edition. Bear in mind that many of the book's code samples involve camera input or video input/output, which is not well suited to the Jupyter server environment, so there is more to explore beyond Jupyter!\n",
    "\n",
    "## Upgrading OpenCV and running the compatibility script\n",
    "\n",
    "**IMPORTANT:** Run the scripts in this section first and run them in order; otherwise, code in subsequent sections may fail or hang.\n",
    "\n",
    "If you are running this Notebook in Google Colab or another environment where OpenCV might not be up-to-date, run the following command to upgrade the OpenCV pip package:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f28b41b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install opencv-contrib-python --upgrade"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d05e28d",
   "metadata": {},
   "source": [
    "If the preceding command's output includes a prompt to restart the kernel, do restart it.\n",
    "\n",
    "Now, run the following script, which provides a compatibility layer between OpenCV and Jupyter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9af37f03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load ../compat/jupyter_compat.py\n",
    "import os\n",
    "\n",
    "import cv2\n",
    "import numpy\n",
    "import PIL.Image\n",
    "\n",
    "from IPython import display\n",
    "from urllib.request import urlopen\n",
    "\n",
    "\n",
    "def cv2_imshow(winname, mat):\n",
    "    mat = mat.clip(0, 255).astype('uint8')\n",
    "    if mat.ndim == 3:\n",
    "        if mat.shape[2] == 4:\n",
    "            mat = cv2.cvtColor(mat, cv2.COLOR_BGRA2RGBA)\n",
    "        else:\n",
    "            mat = cv2.cvtColor(mat, cv2.COLOR_BGR2RGB)\n",
    "    display.display(PIL.Image.fromarray(mat))\n",
    "\n",
    "cv2.imshow = cv2_imshow\n",
    "\n",
    "\n",
    "def cv2_waitKey(delay=0):\n",
    "    return -1\n",
    "\n",
    "cv2.waitKey = cv2_waitKey\n",
    "\n",
    "\n",
    "def cv2_imread(filename, flags=cv2.IMREAD_COLOR):\n",
    "    if os.path.exists(filename):\n",
    "        image = cv2._imread(filename, flags)\n",
    "    else:\n",
    "        url = f'https://github.com/PacktPublishing/Learning-OpenCV-5-Computer-Vision-with-Python-Fourth-Edition/raw/main/*/{filename}'\n",
    "        resp = urlopen(url)\n",
    "        image = numpy.asarray(bytearray(resp.read()), dtype='uint8')\n",
    "        image = cv2.imdecode(image, flags)\n",
    "    return image\n",
    "\n",
    "# Cache the original implementation of `imread`, if we have not already\n",
    "# done so on a previous run of this cell.\n",
    "if '_imread' not in dir(cv2):\n",
    "    cv2._imread = cv2.imread\n",
    "\n",
    "cv2.imread = cv2_imread\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7748f33",
   "metadata": {},
   "source": [
    "What did we just do? We imported OpenCV and we replaced some of OpenCV's I/O functions with our own functions that do not rely on a windowed environment or on a local filesystem.\n",
    "\n",
    "## Applying high-pass and low-pass filters\n",
    "\n",
    "Let's experiment with high-pass filters (HPFs), which can highlight the edges in an image, and low-pass filters (LPFs), which can blur an image.\n",
    "\n",
    "Run the following script, which applies HPFs and LPFs to a photo of a statue of an angel, with a clear sky in the background:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6366f56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load hpf.py\n",
    "import cv2\n",
    "import numpy as np\n",
    "from scipy import ndimage\n",
    "\n",
    "kernel_3x3 = np.array([[-1, -1, -1],\n",
    "                       [-1,  8, -1],\n",
    "                       [-1, -1, -1]])\n",
    "\n",
    "kernel_5x5 = np.array([[-1, -1, -1, -1, -1],\n",
    "                       [-1,  1,  2,  1, -1],\n",
    "                       [-1,  2,  4,  2, -1],\n",
    "                       [-1,  1,  2,  1, -1],\n",
    "                       [-1, -1, -1, -1, -1]])\n",
    "\n",
    "img = cv2.imread(\"../images/statue_small.jpg\",\n",
    "                 cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "k3 = ndimage.convolve(img, kernel_3x3)\n",
    "k5 = ndimage.convolve(img, kernel_5x5)\n",
    "\n",
    "blurred = cv2.GaussianBlur(img, (17,17), 0)\n",
    "g_hpf = img - blurred\n",
    "\n",
    "cv2.imshow(\"3x3\", k3)\n",
    "cv2.imshow(\"5x5\", k5)\n",
    "cv2.imshow(\"blurred\", blurred)\n",
    "cv2.imshow(\"g_hpf\", g_hpf)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ef736dc",
   "metadata": {},
   "source": [
    "You probably see that a lot of noise is highlighted, as well as real edges. However, if we blur the image, the noise is reduced. Experiment with the kernel sizes and values to see how the results are affected.\n",
    "\n",
    "## Edge detection with Canny\n",
    "\n",
    "For better edge detection results, we can apply the Canny algorithm to the same image, as follows:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e0d0de3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load canny.py\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "img = cv2.imread(\"../images/statue_small.jpg\", 0)\n",
    "cv2.imwrite(\"canny.jpg\", cv2.Canny(img, 200, 300))\n",
    "cv2.imshow(\"canny\", cv2.imread(\"canny.jpg\"))\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87327997",
   "metadata": {},
   "source": [
    "The `Canny` function's threshold parameters (such as `200, 300`) determine how sensitive the edge detector is. The first threshold affects the filter's first pass where it looks for any edges, and the second threshold affects the filter's second pass where it attempts to find more edges connected to the first ones. Experiment with the parameters to see how they affect the result.\n",
    "\n",
    "## Bounding box, minimum area rectangle, and minimum enclosing circle\n",
    "\n",
    "OpenCV is effective at detecting and analyzing contours in high-contrast images, such as illustrations. The following script detects contours in an illustration of Thor's Hammer (a prominent symbol from Norse mythology), and then it analyzes those contours to find a bounding box, minimum area rectangle, and minimum enclosing circle:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74e39147",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load contours_2.py\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "OPENCV_MAJOR_VERSION = int(cv2.__version__.split('.')[0])\n",
    "\n",
    "img = cv2.pyrDown(cv2.imread(\"../images/hammer.jpg\"))\n",
    "\n",
    "ret, thresh = cv2.threshold(cv2.cvtColor(img, cv2.COLOR_BGR2GRAY),\n",
    "                            127, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "if OPENCV_MAJOR_VERSION >= 4:\n",
    "    # OpenCV 4 or a later version is being used.\n",
    "    contours, hier = cv2.findContours(thresh, cv2.RETR_EXTERNAL,\n",
    "                                      cv2.CHAIN_APPROX_SIMPLE)\n",
    "else:\n",
    "    # OpenCV 3 or an earlier version is being used.\n",
    "    # cv2.findContours has an extra return value.\n",
    "    # The extra return value is the thresholded image, which is\n",
    "    # unchanged, so we can ignore it.\n",
    "    _, contours, hier = cv2.findContours(thresh, cv2.RETR_EXTERNAL,\n",
    "                                         cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "for c in contours:\n",
    "    # find bounding box coordinates\n",
    "    x, y, w, h = cv2.boundingRect(c)\n",
    "    cv2.rectangle(img, (x,y), (x+w, y+h), (0, 255, 0), 2)\n",
    "\n",
    "    # find minimum area\n",
    "    rect = cv2.minAreaRect(c)\n",
    "    # calculate coordinates of the minimum area rectangle\n",
    "    box = cv2.boxPoints(rect)\n",
    "    # normalize coordinates to integers\n",
    "    box = np.int0(box)\n",
    "    # draw contours\n",
    "    cv2.drawContours(img, [box], 0, (0, 0, 255), 3)\n",
    "\n",
    "    # calculate center and radius of minimum enclosing circle\n",
    "    (x, y), radius = cv2.minEnclosingCircle(c)\n",
    "    # cast to integers\n",
    "    center = (int(x), int(y))\n",
    "    radius = int(radius)\n",
    "    # draw the circle\n",
    "    img = cv2.circle(img, center, radius, (0, 255, 0), 2)\n",
    "\n",
    "cv2.drawContours(img, contours, -1, (255, 0, 0), 1)\n",
    "cv2.imshow(\"contours\", img)\n",
    "\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b224f223",
   "metadata": {},
   "source": [
    "Next, let's look at how to generate other kinds of geometric shapes that more tightly fit the detected contours.\n",
    "\n",
    "## Convex contours and the Douglas-Peucker algorithm\n",
    "\n",
    "The Douglas-Peucker algorithm, as implemented in OpenCV's `approxPolyDP` function, can approximate contours as polygons, with a specified level of precision. Moreover, the `convexHull` function can find a convex shape that best fits the contours. Here is an example where we applies these two functions to the contours of Thor's Hammer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5a5a470",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load contours_hull.py\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "OPENCV_MAJOR_VERSION = int(cv2.__version__.split('.')[0])\n",
    "\n",
    "img = cv2.pyrDown(cv2.imread(\"../images/hammer.jpg\"))\n",
    "\n",
    "ret, thresh = cv2.threshold(cv2.cvtColor(img, cv2.COLOR_BGR2GRAY),\n",
    "                            127, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "if OPENCV_MAJOR_VERSION >= 4:\n",
    "    # OpenCV 4 or a later version is being used.\n",
    "    contours, hier = cv2.findContours(thresh, cv2.RETR_EXTERNAL,\n",
    "                                      cv2.CHAIN_APPROX_SIMPLE)\n",
    "else:\n",
    "    # OpenCV 3 or an earlier version is being used.\n",
    "    # cv2.findContours has an extra return value.\n",
    "    # The extra return value is the thresholded image, which is\n",
    "    # unchanged, so we can ignore it.\n",
    "    _, contours, hier = cv2.findContours(thresh, cv2.RETR_EXTERNAL,\n",
    "                                         cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "black = np.zeros_like(img)\n",
    "for cnt in contours:\n",
    "    epsilon = 0.01 * cv2.arcLength(cnt,True)\n",
    "    approx = cv2.approxPolyDP(cnt,epsilon,True)\n",
    "    hull = cv2.convexHull(cnt)\n",
    "    cv2.drawContours(black, [cnt], -1, (0, 255, 0), 2)\n",
    "    cv2.drawContours(black, [approx], -1, (255, 255, 0), 2)\n",
    "    cv2.drawContours(black, [hull], -1, (0, 0, 255), 2)\n",
    "\n",
    "cv2.imshow(\"hull\", black)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "569d42fe",
   "metadata": {},
   "source": [
    "Try adjusting the `epsilon` parameter to see how it affects the results of `approxPolyDP`.\n",
    "\n",
    "\n",
    "## Detecting lines\n",
    "\n",
    "While OpenCV's contour detection works well on illustrations, it is less effective when applied to photographs or other noisy, detailed images. If we need to detect simple geometric shapes in photographs, a more robust option is to use a combination of the Canny and Hough algorithms.\n",
    "\n",
    "The following code sample uses Canny and Hough to detect lines in a photo of a train platform:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05780806",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load hough_lines.py\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "img = cv2.imread('../images/houghlines5.jpg')\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "edges = cv2.Canny(gray, 50, 120)\n",
    "\n",
    "lines = cv2.HoughLinesP(edges, rho=1,\n",
    "                        theta=np.pi/180.0,\n",
    "                        threshold=20,\n",
    "                        minLineLength=40,\n",
    "                        maxLineGap=5)\n",
    "for line in lines:\n",
    "    x1, y1, x2, y2 = line[0]\n",
    "    cv2.line(img, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "\n",
    "cv2.imshow(\"edges\", edges)\n",
    "cv2.imshow(\"lines\", img)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cba4720",
   "metadata": {},
   "source": [
    "Try adjusting `minLineLength`, `maxLineGap`, and other parameters to see how the detection results are affected.\n",
    "\n",
    "## Detecting circles\n",
    "\n",
    "Likewise, the Canny and Hough algorithms can be used for circle detection. The `HoughCircles` function actually implements both Canny and Hough together, so we do not need to call the `Canny` function separately. Here is an example, where we detect circles in a stylized image of our solar system's planets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce538b51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load hough_circles.py\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "planets = cv2.imread(\"../images/planet_glow.jpg\")\n",
    "gray_img = cv2.cvtColor(planets, cv2.COLOR_BGR2GRAY)\n",
    "gray_img = cv2.medianBlur(gray_img, 5)\n",
    "\n",
    "circles = cv2.HoughCircles(gray_img, cv2.HOUGH_GRADIENT,\n",
    "                           1, 120, param1=90, param2=40,\n",
    "                           minRadius=0, maxRadius=0)\n",
    "\n",
    "if circles is not None:\n",
    "    circles = np.uint16(np.around(circles))\n",
    "\n",
    "    for i in circles[0,:]:\n",
    "        # draw the outer circle\n",
    "        cv2.circle(planets, (i[0], i[1]), i[2],\n",
    "                   (0, 255, 0), 2)\n",
    "        # draw the center of the circle\n",
    "        cv2.circle(planets, (i[0], i[1]), 2,\n",
    "                   (0, 0, 255), 3)\n",
    "\n",
    "cv2.imwrite(\"planets_circles.jpg\", planets)\n",
    "cv2.imshow(\"HoughCircles\", planets)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93178f8f",
   "metadata": {},
   "source": [
    "Again, try adjusting the parameters to see how the results change.\n",
    "\n",
    "# Summary\n",
    "\n",
    "That is all for now! Please refer to the book and to the GitHub repository for additional samples, including integration with an interactive camera application."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
