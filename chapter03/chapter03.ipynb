{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2532e053",
   "metadata": {},
   "source": [
    "# Chapter 3: Processing Images with OpenCV\n",
    "\n",
    "This Jupyter Notebook allows you to interactively edit and run a subset of the code samples from the corresponding chapter in our book, *Learning OpenCV 5 Computer Vision with Python 3*.\n",
    "\n",
    "Any Jupyter server should be capable of running the Notebook, even if the sample input images files are not available in the server's local filesystem. For example, you can run the Notebook in Google Colab by opening the following link in your Web browser: https://colab.research.google.com/github/PacktPublishing/Learning-OpenCV-5-Computer-Vision-with-Python-Fourth-Edition/blob/main/chapter03/chapter03.ipynb. Specifically, this link opens the Notebook's latest version, hosted on GitHub.\n",
    "\n",
    "For additional code samples and instructions, please refer to the book and to the GitHub repository at https://github.com/PacktPublishing/Learning-OpenCV-5-Computer-Vision-with-Python-Fourth-Edition. Bear in mind that many of the book's code samples involve camera input or video input/output, which is not well suited to the Jupyter server environment, so there is more to explore beyond Jupyter!\n",
    "\n",
    "## Upgrading OpenCV and running the compatibility script\n",
    "\n",
    "**IMPORTANT:** Run the scripts in this section first and run them in order; otherwise, code in subsequent sections may fail or hang.\n",
    "\n",
    "If you are running this Notebook in Google Colab or another environment where OpenCV might not be up-to-date, run the following command to upgrade the OpenCV pip package:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f28b41b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install opencv-contrib-python --upgrade"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d05e28d",
   "metadata": {},
   "source": [
    "If the preceding command's output includes a prompt to restart the kernel, do restart it.\n",
    "\n",
    "Now, run the following script, which provides a compatibility layer between OpenCV and Jupyter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9af37f03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load ../compat/jupyter_compat.py\n",
    "import os\n",
    "\n",
    "import cv2\n",
    "import numpy\n",
    "import PIL.Image\n",
    "\n",
    "from IPython import display\n",
    "from urllib.request import urlopen\n",
    "\n",
    "\n",
    "def cv2_imshow(winname, mat):\n",
    "    mat = mat.clip(0, 255).astype('uint8')\n",
    "    if mat.ndim == 3:\n",
    "        if mat.shape[2] == 4:\n",
    "            mat = cv2.cvtColor(mat, cv2.COLOR_BGRA2RGBA)\n",
    "        else:\n",
    "            mat = cv2.cvtColor(mat, cv2.COLOR_BGR2RGB)\n",
    "    display.display(PIL.Image.fromarray(mat))\n",
    "\n",
    "cv2.imshow = cv2_imshow\n",
    "\n",
    "\n",
    "def cv2_waitKey(delay=0):\n",
    "    return -1\n",
    "\n",
    "cv2.waitKey = cv2_waitKey\n",
    "\n",
    "\n",
    "def cv2_imread(filename, flags=cv2.IMREAD_COLOR):\n",
    "    if os.path.exists(filename):\n",
    "        image = cv2._imread(filename, flags)\n",
    "    else:\n",
    "        url = f'https://github.com/PacktPublishing/Learning-OpenCV-5-Computer-Vision-with-Python-Fourth-Edition/raw/main/*/{filename}'\n",
    "        resp = urlopen(url)\n",
    "        image = numpy.asarray(bytearray(resp.read()), dtype='uint8')\n",
    "        image = cv2.imdecode(image, flags)\n",
    "    return image\n",
    "\n",
    "# Cache the original implementation of `imread`, if we have not already\n",
    "# done so on a previous run of this cell.\n",
    "if '_imread' not in dir(cv2):\n",
    "    cv2._imread = cv2.imread\n",
    "\n",
    "cv2.imread = cv2_imread\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7748f33",
   "metadata": {},
   "source": [
    "What did we just do? We imported OpenCV and we replaced some of OpenCV's I/O functions with our own functions that do not rely on a windowed environment or on a local filesystem.\n",
    "\n",
    "## Applying high-pass and low-pass filters\n",
    "\n",
    "Let's experiment with high-pass filters (HPFs), which can highlight the edges in an image, and low-pass filters (LPFs), which can blur an image.\n",
    "\n",
    "Run the following script, which applies HPFs and LPFs to a photo of a statue of an angel, with a clear sky in the background:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6366f56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load hpf.py\n",
    "import cv2\n",
    "import numpy as np\n",
    "from scipy import ndimage\n",
    "\n",
    "kernel_3x3 = np.array([[-1, -1, -1],\n",
    "                       [-1,  8, -1],\n",
    "                       [-1, -1, -1]])\n",
    "\n",
    "kernel_5x5 = np.array([[-1, -1, -1, -1, -1],\n",
    "                       [-1,  1,  2,  1, -1],\n",
    "                       [-1,  2,  4,  2, -1],\n",
    "                       [-1,  1,  2,  1, -1],\n",
    "                       [-1, -1, -1, -1, -1]])\n",
    "\n",
    "img = cv2.imread(\"../images/statue_small.jpg\",\n",
    "                 cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "k3 = ndimage.convolve(img, kernel_3x3)\n",
    "k5 = ndimage.convolve(img, kernel_5x5)\n",
    "\n",
    "blurred = cv2.GaussianBlur(img, (17, 17), 0)\n",
    "g_hpf = img - blurred\n",
    "\n",
    "cv2.imshow(\"3x3\", k3)\n",
    "cv2.imshow(\"5x5\", k5)\n",
    "cv2.imshow(\"blurred\", blurred)\n",
    "cv2.imshow(\"g_hpf\", g_hpf)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ef736dc",
   "metadata": {},
   "source": [
    "You probably see that a lot of noise is highlighted, as well as real edges. However, if we blur the image, the noise is reduced. Experiment with the kernel sizes and values to see how the results are affected.\n",
    "\n",
    "## Edge detection with Canny\n",
    "\n",
    "For better edge detection results, we can apply the Canny algorithm to the same image, as follows:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e0d0de3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load canny.py\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "img = cv2.imread(\"../images/statue_small.jpg\",\n",
    "                 cv2.IMREAD_GRAYSCALE)\n",
    "canny_img = cv2.Canny(img, 200, 300)\n",
    "cv2.imshow(\"canny\", canny_img)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87327997",
   "metadata": {},
   "source": [
    "The `Canny` function's threshold parameters (such as `200, 300`) determine how sensitive the edge detector is. The first threshold affects the filter's first pass where it looks for any edges, and the second threshold affects the filter's second pass where it attempts to find more edges connected to the first ones. Experiment with the parameters to see how they affect the result.\n",
    "\n",
    "## Edge detection with the `EdgeDrawing` class\n",
    "\n",
    "`opencv_contrib` (specifically, the `ximgproc` module) contains a class called `EdgeDrawing`, which implements a set of algorithms for detecting and drawing edge segments, lines, circles, and ellipses. The Edge Drawing or ED algorithms are the work of Cuneyt Akinlar and Cihan Topal. Their implementation in `opencv_contrib` is the work of Suleyman Turkmen, who is also one of our technical reviewers for *Learning OpenCV 5 Computer Vision with Python 3*, and he has kindly contributed this chapter's sample code for `EdgeDrawing`.\n",
    "\n",
    "Often, `EdgeDrawing` gives better and faster results than older algorithms such as Canny. Also, `EdgeDrawing` organizes its detection results in a more sophisticated way. To illustrate this point, the following sample code uses `EdgeDrawing` to colorize various connected edge segments, based on the input photo of the angel statue:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "545833b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load edge_drawing_segments.py\n",
    "import random as rng\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "img = cv2.imread(\"../images/statue_small.jpg\",\n",
    "                 cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "h, w = img.shape\n",
    "viz = np.zeros((h, w, 3), dtype=np.uint8)\n",
    "\n",
    "edge_drawing = cv2.ximgproc.createEdgeDrawing()\n",
    "\n",
    "# Detect edges and get the resulting edge segments.\n",
    "edge_drawing.detectEdges(img)\n",
    "segments = edge_drawing.getSegments()\n",
    "\n",
    "# Draw the detected edge segments.\n",
    "for segment in segments:\n",
    "    color = (rng.randint(16, 256),\n",
    "             rng.randint(16, 256),\n",
    "             rng.randint(16, 256))\n",
    "    cv2.polylines(viz, [segment], False, color, 1, cv2.LINE_8)\n",
    "\n",
    "cv2.imshow(\"Detected edge segments\", viz)\n",
    "\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02adb049",
   "metadata": {},
   "source": [
    "Later in this notebook, we will compare `EdgeDrawing`'s shape detection capabilities to another family of algorithms called Hough algorithms. First, though, let's look at a couple of general problems of contour detection and analysis.\n",
    "\n",
    "## Bounding box, minimum area rectangle, and minimum enclosing circle\n",
    "\n",
    "OpenCV is effective at detecting and analyzing contours in high-contrast images, such as illustrations. The following script detects contours in an illustration of Thor's Hammer (a prominent symbol from Norse mythology), and then it analyzes those contours to find a bounding box, minimum area rectangle, and minimum enclosing circle:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74e39147",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load contours_2.py\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "OPENCV_MAJOR_VERSION = int(cv2.__version__.split('.')[0])\n",
    "\n",
    "img = cv2.pyrDown(cv2.imread(\"../images/hammer.jpg\"))\n",
    "\n",
    "ret, thresh = cv2.threshold(cv2.cvtColor(img, cv2.COLOR_BGR2GRAY),\n",
    "                            127, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "if OPENCV_MAJOR_VERSION >= 4:\n",
    "    # OpenCV 4 or a later version is being used.\n",
    "    contours, hier = cv2.findContours(thresh, cv2.RETR_EXTERNAL,\n",
    "                                      cv2.CHAIN_APPROX_SIMPLE)\n",
    "else:\n",
    "    # OpenCV 3 or an earlier version is being used.\n",
    "    # cv2.findContours has an extra return value.\n",
    "    # The extra return value is the thresholded image, which (in\n",
    "    # OpenCV 3.1 or an earlier version) may have been modified, but\n",
    "    # we can ignore it.\n",
    "    _, contours, hier = cv2.findContours(thresh, cv2.RETR_EXTERNAL,\n",
    "                                         cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "for c in contours:\n",
    "    # find bounding box coordinates\n",
    "    x, y, w, h = cv2.boundingRect(c)\n",
    "    cv2.rectangle(img, (x,y), (x+w, y+h), (0, 255, 0), 2)\n",
    "\n",
    "    # find minimum area\n",
    "    rect = cv2.minAreaRect(c)\n",
    "    # calculate coordinates of the minimum area rectangle\n",
    "    box = cv2.boxPoints(rect)\n",
    "    # normalize coordinates to integers\n",
    "    box = np.int0(box)\n",
    "    # draw contours\n",
    "    cv2.drawContours(img, [box], 0, (0, 0, 255), 3)\n",
    "\n",
    "    # calculate center and radius of minimum enclosing circle\n",
    "    (x, y), radius = cv2.minEnclosingCircle(c)\n",
    "    # cast to integers\n",
    "    center = (int(x), int(y))\n",
    "    radius = int(radius)\n",
    "    # draw the circle\n",
    "    img = cv2.circle(img, center, radius, (0, 255, 0), 2)\n",
    "\n",
    "cv2.drawContours(img, contours, -1, (255, 0, 0), 1)\n",
    "cv2.imshow(\"contours\", img)\n",
    "\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b224f223",
   "metadata": {},
   "source": [
    "Next, let's look at how to generate other kinds of geometric shapes that more tightly fit the detected contours.\n",
    "\n",
    "## Convex contours and the Douglas-Peucker algorithm\n",
    "\n",
    "The Douglas-Peucker algorithm, as implemented in OpenCV's `approxPolyDP` function, can approximate contours as polygons, with a specified level of precision. Moreover, the `convexHull` function can find a convex shape that best fits the contours. Here is an example where we applies these two functions to the contours of Thor's Hammer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5a5a470",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load contours_hull.py\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "OPENCV_MAJOR_VERSION = int(cv2.__version__.split('.')[0])\n",
    "\n",
    "img = cv2.pyrDown(cv2.imread(\"../images/hammer.jpg\"))\n",
    "\n",
    "ret, thresh = cv2.threshold(cv2.cvtColor(img, cv2.COLOR_BGR2GRAY),\n",
    "                            127, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "if OPENCV_MAJOR_VERSION >= 4:\n",
    "    # OpenCV 4 or a later version is being used.\n",
    "    contours, hier = cv2.findContours(thresh, cv2.RETR_EXTERNAL,\n",
    "                                      cv2.CHAIN_APPROX_SIMPLE)\n",
    "else:\n",
    "    # OpenCV 3 or an earlier version is being used.\n",
    "    # cv2.findContours has an extra return value.\n",
    "    # The extra return value is the thresholded image, which (in\n",
    "    # OpenCV 3.1 or an earlier version) may have been modified, but\n",
    "    # we can ignore it.\n",
    "    _, contours, hier = cv2.findContours(thresh, cv2.RETR_EXTERNAL,\n",
    "                                         cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "black = np.zeros_like(img)\n",
    "for cnt in contours:\n",
    "    epsilon = 0.01 * cv2.arcLength(cnt,True)\n",
    "    approx = cv2.approxPolyDP(cnt,epsilon,True)\n",
    "    hull = cv2.convexHull(cnt)\n",
    "    cv2.drawContours(black, [cnt], -1, (0, 255, 0), 2)\n",
    "    cv2.drawContours(black, [approx], -1, (255, 255, 0), 2)\n",
    "    cv2.drawContours(black, [hull], -1, (0, 0, 255), 2)\n",
    "\n",
    "cv2.imshow(\"hull\", black)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "569d42fe",
   "metadata": {},
   "source": [
    "Try adjusting the `epsilon` parameter to see how it affects the results of `approxPolyDP`.\n",
    "\n",
    "\n",
    "## Detecting lines\n",
    "\n",
    "While OpenCV's contour detection works well on illustrations, it is less effective when applied to photographs or other noisy, detailed images. If we need to detect simple geometric shapes in photographs, a more robust option is to use a combination of the Canny and Hough algorithms.\n",
    "\n",
    "The following code sample uses Canny and Hough to detect lines in a photo of a train platform:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05780806",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load hough_lines.py\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "img = cv2.imread('../images/houghlines5.jpg')\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "edges = cv2.Canny(gray, 50, 120)\n",
    "\n",
    "lines = cv2.HoughLinesP(edges, rho=1,\n",
    "                        theta=np.pi/180.0,\n",
    "                        threshold=20,\n",
    "                        minLineLength=40,\n",
    "                        maxLineGap=5)\n",
    "for line in lines:\n",
    "    line = line.squeeze()\n",
    "    x1, y1, x2, y2 = line\n",
    "    cv2.line(img, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "\n",
    "cv2.imshow(\"edges\", edges)\n",
    "cv2.imshow(\"lines\", img)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cba4720",
   "metadata": {},
   "source": [
    "Try adjusting `minLineLength`, `maxLineGap`, and other parameters to see how the detection results are affected.\n",
    "\n",
    "The `EdgeDrawing` class from `opencv_contrib` also supports line detection, often with better results than Canny and Hough. Using the photo of the train platform as input again, we can detect lines with `EdgeDrawing` as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "818e9126",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load edge_drawing_lines.py\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "img = cv2.imread('../images/houghlines5.jpg')\n",
    "gray_img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "edge_drawing = cv2.ximgproc.createEdgeDrawing()\n",
    "\n",
    "edge_drawing_params = cv2.ximgproc_EdgeDrawing_Params()\n",
    "edge_drawing_params.MinLineLength = 20\n",
    "\n",
    "edge_drawing.setParams(edge_drawing_params)\n",
    "\n",
    "# Detect edges.\n",
    "edge_drawing.detectEdges(gray_img)\n",
    "\n",
    "# Detect lines based on the edges and the specified parameters.\n",
    "lines = edge_drawing.detectLines()\n",
    "\n",
    "# Draw the detected lines.\n",
    "if lines is not None:\n",
    "    lines = np.uint16(np.around(lines))\n",
    "    for line in lines:\n",
    "        line = line.squeeze()\n",
    "        cv2.line(img, (line[0], line[1]),\n",
    "        (line[2], line[3]), (0, 255, 0), 2, cv2.LINE_AA)\n",
    "\n",
    "cv2.imshow(\"Detected lines\", img)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a42ac3cf",
   "metadata": {},
   "source": [
    "Try adjusting `MinLineLength` to see how the detection results are affected.\n",
    "\n",
    "## Detecting circles\n",
    "\n",
    "Circle detection is another problem that the Canny and Hough algorithms can soolve. The `HoughCircles` function actually implements both Canny and Hough together, so we do not need to call the `Canny` function separately. Here is an example, where we detect circles in a stylized image of our solar system's planets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce538b51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load hough_circles.py\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "planets = cv2.imread(\"../images/planet_glow.jpg\")\n",
    "gray_img = cv2.cvtColor(planets, cv2.COLOR_BGR2GRAY)\n",
    "gray_img = cv2.medianBlur(gray_img, 5)\n",
    "\n",
    "circles = cv2.HoughCircles(gray_img, cv2.HOUGH_GRADIENT,\n",
    "                           1, 120, param1=90, param2=40,\n",
    "                           minRadius=0, maxRadius=0)\n",
    "\n",
    "if circles is not None:\n",
    "    circles = np.uint16(np.around(circles))\n",
    "\n",
    "    for i in circles[0,:]:\n",
    "        # draw the outer circle\n",
    "        cv2.circle(planets, (i[0], i[1]), i[2],\n",
    "                   (0, 255, 0), 2)\n",
    "        # draw the center of the circle\n",
    "        cv2.circle(planets, (i[0], i[1]), 2,\n",
    "                   (0, 0, 255), 3)\n",
    "\n",
    "cv2.imwrite(\"planets_circles.jpg\", planets)\n",
    "cv2.imshow(\"HoughCircles\", planets)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4111f0ff",
   "metadata": {},
   "source": [
    "Again, try adjusting the parameters to see how the results change.\n",
    "\n",
    "The multi-purpose `EdgeDrawing` class from `opencv_contrib` is also effective at detecting circles, as well as ellipses. The following code uses `EdgeDrawing` to find circular and elliptical outlines in the same stylized image of the planets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c28eb17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load edge_drawing_ellipses.py\n",
    "import random as rng\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "planets = cv2.imread(\"../images/planet_glow.jpg\")\n",
    "gray_img = cv2.cvtColor(planets, cv2.COLOR_BGR2GRAY)\n",
    "gray_img = cv2.medianBlur(gray_img, 5)\n",
    "\n",
    "segments_viz = planets.copy()\n",
    "ellipses_viz = planets.copy()\n",
    "\n",
    "edge_drawing = cv2.ximgproc.createEdgeDrawing()\n",
    "\n",
    "# Detect edges and get the resulting edge segments.\n",
    "edge_drawing.detectEdges(gray_img)\n",
    "segments = edge_drawing.getSegments()\n",
    "\n",
    "# Detect circles and ellipses based on the detected edges.\n",
    "ellipses = edge_drawing.detectEllipses()\n",
    "\n",
    "# Draw the detected edge segments.\n",
    "for segment in segments:\n",
    "    color = (rng.randint(16, 256),\n",
    "             rng.randint(16, 256),\n",
    "             rng.randint(16, 256))\n",
    "    cv2.polylines(segments_viz, [segment], False, color, 1,\n",
    "                  cv2.LINE_8)\n",
    "\n",
    "# Draw the detected circles and ellipses.\n",
    "if ellipses is not None:\n",
    "    for ellipse in ellipses:\n",
    "        ellipse = ellipse.squeeze()\n",
    "        center = (int(ellipse[0]), int(ellipse[1]))\n",
    "        axes = (int(ellipse[2] + ellipse[3]),\n",
    "                int(ellipse[2] + ellipse[4]))\n",
    "        angle = ellipse[5]\n",
    "        if ellipse[2] == 0:  # Ellipse\n",
    "            color = (0, 0, 255)\n",
    "        else:  # Circle\n",
    "            color = (0, 255, 0)\n",
    "        cv2.ellipse(ellipses_viz, center, axes, angle, 0, 360,\n",
    "                    color, 2, cv2.LINE_AA)\n",
    "\n",
    "cv2.imwrite(\"planets_edge_drawing_segments.jpg\", segments_viz)\n",
    "cv2.imwrite(\"planets_edge_drawing_ellipses.jpg\", ellipses_viz)\n",
    "\n",
    "cv2.imshow(\"Detected edge segments\", segments_viz)\n",
    "cv2.imshow(\"Detected circles (green) and ellipses (red)\", ellipses_viz)\n",
    "\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93178f8f",
   "metadata": {},
   "source": [
    "Note how the detected line segments (in the script's first output image) are the basis of the detected ellipses and circles (in the script's second output image).\n",
    "\n",
    "# Summary\n",
    "\n",
    "That is all for now! Please refer to the book and to the GitHub repository for additional samples, including integration with an interactive camera application."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
