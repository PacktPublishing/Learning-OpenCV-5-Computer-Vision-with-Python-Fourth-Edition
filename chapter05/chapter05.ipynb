{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2532e053",
   "metadata": {},
   "source": [
    "# Chapter 5: Detecting and Recognizing Faces\n",
    "\n",
    "This Jupyter Notebook allows you to interactively edit and run a subset of the code samples from the corresponding chapter in our book, *Learning OpenCV 5 Computer Vision with Python 3*.\n",
    "\n",
    "Any Jupyter server should be capable of running the Notebook, even if the sample input images files are not available in the server's local filesystem. For example, you can run the Notebook in Google Colab by opening the following link in your Web browser: https://colab.research.google.com/github/PacktPublishing/Learning-OpenCV-5-Computer-Vision-with-Python-Fourth-Edition/blob/main/chapter05/chapter05.ipynb. Specifically, this link opens the Notebook's latest version, hosted on GitHub.\n",
    "\n",
    "For additional code samples and instructions, please refer to the book and to the GitHub repository at https://github.com/PacktPublishing/Learning-OpenCV-5-Computer-Vision-with-Python-Fourth-Edition. Bear in mind that many of the book's code samples involve camera input or video input/output, which is not well suited to the Jupyter server environment, so there is more to explore beyond Jupyter!\n",
    "\n",
    "## Running the compatibility script\n",
    "\n",
    "**Do this first; otherwise, code in subsequent sections may hang.**\n",
    "\n",
    "Run the following script, which provides a compatibility layer between OpenCV and Jupyter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9af37f03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load ../compat/jupyter_compat.py\n",
    "import cv2\n",
    "import numpy\n",
    "import PIL.Image\n",
    "\n",
    "from IPython import display\n",
    "from urllib.request import urlopen\n",
    "\n",
    "\n",
    "def cv2_imshow(winname, mat):\n",
    "    mat = mat.clip(0, 255).astype('uint8')\n",
    "    if mat.ndim == 3:\n",
    "        if mat.shape[2] == 4:\n",
    "            mat = cv2.cvtColor(mat, cv2.COLOR_BGRA2RGBA)\n",
    "        else:\n",
    "            mat = cv2.cvtColor(mat, cv2.COLOR_BGR2RGB)\n",
    "    display.display(PIL.Image.fromarray(mat))\n",
    "\n",
    "cv2.imshow = cv2_imshow\n",
    "\n",
    "\n",
    "def cv2_waitKey(delay=0):\n",
    "    return -1\n",
    "\n",
    "cv2.waitKey = cv2_waitKey\n",
    "\n",
    "\n",
    "def cv2_imread(filename, flags=cv2.IMREAD_COLOR):\n",
    "    url = f'https://github.com/PacktPublishing/Learning-OpenCV-5-Computer-Vision-with-Python-Fourth-Edition/raw/main/*/{filename}'\n",
    "    resp = urlopen(url)\n",
    "    image = numpy.asarray(bytearray(resp.read()), dtype='uint8')\n",
    "    image = cv2.imdecode(image, flags)\n",
    "    return image\n",
    "\n",
    "cv2.imread = cv2_imread\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7748f33",
   "metadata": {},
   "source": [
    "What did we just do? We imported OpenCV and we replaced some of OpenCV's I/O functions with our own functions that do not rely on a windowed environment or on a local filesystem.\n",
    "\n",
    "## Performing face detection on a still image\n",
    "\n",
    "Let's experiment with an old but good (computationally cost-effective) detection technique: the use of Haar cascades.\n",
    "\n",
    "Run the following script, which uses Haar cascades to try to detect human faces in an image of logs and woodcutters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6366f56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load face_detection_still.py\n",
    "import cv2\n",
    "\n",
    "\n",
    "face_cascade = cv2.CascadeClassifier(\n",
    "    f'{cv2.data.haarcascades}haarcascade_frontalface_default.xml')\n",
    "img = cv2.imread('../images/woodcutters.jpg')\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "faces = face_cascade.detectMultiScale(gray, 1.08, 5)\n",
    "for (x, y, w, h) in faces:\n",
    "    img = cv2.rectangle(img, (x, y), (x+w, y+h), (255, 255, 0), 2)\n",
    "  \n",
    "cv2.imshow('Woodcutters Detected!', img)\n",
    "cv2.imwrite('./woodcutters_detected.png', img)\n",
    "cv2.waitKey(0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ef736dc",
   "metadata": {},
   "source": [
    "You probably see that some but not all of the woodcutters' faces were detected. Try fine-tuning the parameters of `detectMultiScale` to see whether the detection results get better or worse. What types of objects in this image tend to produce false positive detections?\n",
    "\n",
    "# Summary\n",
    "\n",
    "That is all for now! Please refer to the book and to the GitHub repository for several samples of face detection and recognition using webcam input."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
